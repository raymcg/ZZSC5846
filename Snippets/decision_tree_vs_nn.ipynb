{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads datasets, pre-processes them, splitting them into training and testing sets, and then applying two types of models: \n",
    "a neural network model (Multi-Layer Perceptron) and \n",
    "a Decision Tree model, \n",
    "\n",
    "for either classification or regression tasks. \n",
    "\n",
    "The performance of these models is evaluated, and the results are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpath = \"c:\\\\dropbox\\\\variance\\\\unsw\\\\zzsc5836\\\\raw_data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(run_num, prob):\n",
    "\n",
    "    normalise = False\n",
    "    \n",
    "    if prob == 'classifification': #Source:  Pima-Indian diabetes dataset: https://www.kaggle.com/kumargh/pimaindiansdiabetescsv\n",
    "        data_in = genfromtxt(fpath+\"pima.csv\", delimiter=\",\")\n",
    "        data_inputx = data_in[:,0:8] # all features 0, 1, 2, 3, 4, 5, 6, 7 \n",
    "        data_inputy = data_in[:,-1] # this is target - so that last col is selected from data\n",
    "\n",
    "    elif prob == 'regression': # energy - regression prob\n",
    "        data_in = genfromtxt(fpath+'ENB2012_data.csv', delimiter=\",\")  \n",
    "        data_inputx = data_in[:,0:8] # all features 0, - 7\n",
    "        data_inputy = data_in[:,8] # this is target - just the heating load selected from data\n",
    "  \n",
    "\n",
    "    if normalise == True:\n",
    "        transformer = Normalizer().fit(data_inputx)  # fit does nothing.\n",
    "        data_inputx = transformer.transform(data_inputx)\n",
    " \n",
    "\n",
    " \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_inputx, data_inputy, test_size=0.40, random_state=run_num)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    " \n",
    "    \n",
    "def scipy_models(x_train, x_test, y_train, y_test, type_model, hidden, learn_rate, run_num, problem):\n",
    "\n",
    "    print(run_num, ' is our exp run')\n",
    "\n",
    "    tree_depth = 2\n",
    " \n",
    "    if problem == 'classifification':\n",
    "        if type_model ==0: #SGD \n",
    "            model = MLPClassifier(hidden_layer_sizes=(hidden,), random_state=run_num, max_iter=100,solver='sgd',  learning_rate_init=learn_rate ) \n",
    "        elif type_model ==1: #https://scikit-learn.org/stable/modules/tree.html  (see how tree can be visualised)\n",
    "            model = DecisionTreeClassifier(random_state=0, max_depth=tree_depth)\n",
    "\n",
    "    elif problem == 'regression':\n",
    "        if type_model ==0: #SGD \n",
    "            #model = MLPRegressor(hidden_layer_sizes=(hidden,), random_state=run_num, max_iter=100,solver='sgd',  learning_rate_init=learn_rate ) \n",
    "\n",
    "            model = MLPRegressor(hidden_layer_sizes=(hidden*3,), random_state=run_num, max_iter=500, solver='adam',learning_rate_init=learn_rate) \n",
    "        elif type_model ==1: #https://scikit-learn.org/stable/modules/tree.html  (see how tree can be visualised)\n",
    "            model = DecisionTreeRegressor(random_state=0, max_depth=tree_depth)\n",
    "   \n",
    "    # Train the model using the training sets\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    if type_model ==1:\n",
    "        r = export_text(model)\n",
    "        print(r)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    y_pred_train = model.predict(x_train) \n",
    "\n",
    "    if problem == 'regression':\n",
    "        perf_test =  np.sqrt(mean_squared_error(y_test, y_pred_test)) \n",
    "        perf_train=  np.sqrt(mean_squared_error(y_train, y_pred_train)) \n",
    "\n",
    "    if problem == 'classifification': \n",
    "        perf_test = accuracy_score(y_pred_test, y_test) \n",
    "        perf_train = accuracy_score(y_pred_train, y_train) \n",
    "        cm = confusion_matrix(y_pred_test, y_test) \n",
    "        #print(cm, 'is confusion matrix')\n",
    "        #auc = roc_auc_score(y_pred, y_test, average=None) \n",
    "\n",
    "    return perf_test #,perf_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifification  is our problem\n",
      "0  is our exp run\n",
      "0  is our exp run\n",
      "|--- feature_1 <= 154.50\n",
      "|   |--- feature_7 <= 28.50\n",
      "|   |   |--- class: 0.0\n",
      "|   |--- feature_7 >  28.50\n",
      "|   |   |--- class: 0.0\n",
      "|--- feature_1 >  154.50\n",
      "|   |--- feature_5 <= 29.95\n",
      "|   |   |--- class: 0.0\n",
      "|   |--- feature_5 >  29.95\n",
      "|   |   |--- class: 1.0\n",
      "\n",
      "1  is our exp run\n",
      "1  is our exp run\n",
      "|--- feature_1 <= 130.50\n",
      "|   |--- feature_7 <= 27.50\n",
      "|   |   |--- class: 0.0\n",
      "|   |--- feature_7 >  27.50\n",
      "|   |   |--- class: 0.0\n",
      "|--- feature_1 >  130.50\n",
      "|   |--- feature_5 <= 33.25\n",
      "|   |   |--- class: 0.0\n",
      "|   |--- feature_5 >  33.25\n",
      "|   |   |--- class: 1.0\n",
      "\n",
      "2  is our exp run\n",
      "2  is our exp run\n",
      "|--- feature_1 <= 127.50\n",
      "|   |--- feature_0 <= 4.50\n",
      "|   |   |--- class: 0.0\n",
      "|   |--- feature_0 >  4.50\n",
      "|   |   |--- class: 0.0\n",
      "|--- feature_1 >  127.50\n",
      "|   |--- feature_1 <= 165.50\n",
      "|   |   |--- class: 1.0\n",
      "|   |--- feature_1 >  165.50\n",
      "|   |   |--- class: 1.0\n",
      "\n",
      "3  is our exp run\n",
      "3  is our exp run\n",
      "|--- feature_1 <= 144.50\n",
      "|   |--- feature_7 <= 28.50\n",
      "|   |   |--- class: 0.0\n",
      "|   |--- feature_7 >  28.50\n",
      "|   |   |--- class: 0.0\n",
      "|--- feature_1 >  144.50\n",
      "|   |--- feature_1 <= 166.50\n",
      "|   |   |--- class: 1.0\n",
      "|   |--- feature_1 >  166.50\n",
      "|   |   |--- class: 1.0\n",
      "\n",
      "4  is our exp run\n",
      "4  is our exp run\n",
      "|--- feature_1 <= 127.50\n",
      "|   |--- feature_7 <= 28.50\n",
      "|   |   |--- class: 0.0\n",
      "|   |--- feature_7 >  28.50\n",
      "|   |   |--- class: 0.0\n",
      "|--- feature_1 >  127.50\n",
      "|   |--- feature_5 <= 29.95\n",
      "|   |   |--- class: 0.0\n",
      "|   |--- feature_5 >  29.95\n",
      "|   |   |--- class: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_expruns = 5\n",
    "\n",
    "SGD_all = np.zeros(max_expruns) \n",
    "Adam_all = np.zeros(max_expruns) \n",
    "tree_all = np.zeros(max_expruns)  \n",
    "\n",
    "learn_rate = 0.01\n",
    "hidden = 8\n",
    "\n",
    "prob = 'classifification' #  classification  or regression \n",
    "#prob = 'regression' #  classification  or regression \n",
    "\n",
    "\n",
    "# classifcation accurary is reported for classification and RMSE for regression\n",
    "\n",
    "print(prob, ' is our problem')\n",
    "\n",
    "for run_num in range(0,max_expruns): \n",
    "\n",
    "    x_train, x_test, y_train, y_test = read_data(run_num, prob)   \n",
    "    \n",
    "    acc_sgd = scipy_models(x_train, x_test, y_train, y_test, 0, hidden, learn_rate, run_num, prob) #SGD \n",
    "    acc_tree = scipy_models(x_train, x_test, y_train, y_test, 1, hidden, learn_rate,  run_num, prob) #Decision Tree\n",
    "    \n",
    "    SGD_all[run_num] = acc_sgd \n",
    "    tree_all[run_num] = acc_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66558442 0.6461039  0.66558442 0.59415584 0.66558442]  SGD_all\n",
      "0.6474025974025974  mean nn_all\n",
      "0.02767178669176953  std nn_all\n"
     ]
    }
   ],
   "source": [
    "print(SGD_all,' SGD_all')\n",
    "print(np.mean(SGD_all), ' mean nn_all')\n",
    "print(np.std(SGD_all), ' std nn_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72402597 0.70454545 0.73051948 0.71428571 0.78896104] 8  tree_all\n",
      "0.7324675324675325  tree _all\n",
      "0.029586456493232507  tree _all\n"
     ]
    }
   ],
   "source": [
    "print(tree_all, hidden,' tree_all')\n",
    "print(np.mean(tree_all),  ' tree _all')\n",
    "print(np.std(tree_all),  ' tree _all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROGRAM EXPLANATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script is structured to run multiple experiments (defined by max_expruns) where in each run, it trains both a neural network and a Decision Tree model on the dataset, then evaluates their performance based on the problem type (classification or regression). The results across all runs are aggregated and printed at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    np, plt: Aliases for the numpy and matplotlib.pyplot libraries, respectively.\n",
    "\n",
    "    datasets, train_test_split, metrics, etc.: These are various modules and functions imported from sklearn, a machine learning library.\n",
    "\n",
    "    random: The random module is imported but not used in the script.\n",
    "\n",
    "    normalise, transformer: Used for an optional normalization step in the read_data function. normalise is a boolean flag, and transformer is an instance of Normalizer.\n",
    "\n",
    "    data_in, data_inputx, data_inputy: Variables used to store the dataset, its features, and labels respectively.\n",
    "\n",
    "    x_train, x_test, y_train, y_test: These variables represent the training and testing splits of the dataset's features and labels.\n",
    "\n",
    "    type_model, hidden, learn_rate, run_num, problem: Parameters for the scipy_models function. They control the type of model, architecture of the neural network, learning rate, run number, and problem type (classification or regression).\n",
    "\n",
    "    tree_depth: Used to set the depth of the Decision Tree model.\n",
    "\n",
    "    model: Represents the machine learning model, either MLPClassifier/MLPRegressor or DecisionTreeClassifier/DecisionTreeRegressor.\n",
    "\n",
    "    y_pred_test, y_pred_train: Variables to store the predictions of the model on test and train data.\n",
    "\n",
    "    perf_test, perf_train, cm: Variables to store the performance metrics (accuracy, RMSE, confusion matrix) of the model.\n",
    "\n",
    "    max_expruns, SGD_all, Adam_all, tree_all: Used in the main function. max_expruns defines the number of experimental runs, and the other variables are arrays to store performance metrics for each model across runs.\n",
    "\n",
    "    prob: A variable to define the type of problem - classification or regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
