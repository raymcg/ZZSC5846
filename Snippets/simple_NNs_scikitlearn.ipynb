{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE NEURAL NET : BINARY CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[121  24]\n",
      " [ 24 131]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       145\n",
      "           1       0.85      0.85      0.85       155\n",
      "\n",
      "    accuracy                           0.84       300\n",
      "   macro avg       0.84      0.84      0.84       300\n",
      "weighted avg       0.84      0.84      0.84       300\n",
      "\n",
      "Accuracy: 0.84\n",
      "ROC-AUC: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the data using the min-max scaler\n",
    "norm = MinMaxScaler().fit(X_train) # This calculates the min and max values of each feature and records them for applicatin to future data\n",
    "X_train = norm.transform(X_train) # apply the scaler to the training data\n",
    "X_test = norm.transform(X_test) # apply the scaler to the testing data\n",
    "\n",
    "# Create and train the neural network model\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Performance metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.6693561 , -1.49577819, -0.87076638, ..., -1.26733697,\n",
       "         -1.2763343 ,  1.01664321],\n",
       "        [ 0.09337237,  0.78584826,  0.10575379, ..., -0.12270893,\n",
       "          0.6934308 ,  0.91136272],\n",
       "        [-0.90579721, -0.60834121,  0.29514098, ...,  0.83049813,\n",
       "         -0.73733198, -0.5782121 ],\n",
       "        ...,\n",
       "        [-0.20013455, -1.46108168,  1.79701652, ..., -1.50280171,\n",
       "         -1.27473745,  1.60111869],\n",
       "        [ 0.03935575,  0.24868361, -0.47532342, ...,  0.09912579,\n",
       "          0.54269228,  1.20827474],\n",
       "        [ 0.76921528,  0.47076539,  0.16994471, ...,  0.6561162 ,\n",
       "          0.64333186, -2.02100232]]),\n",
       " array([1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI CLASS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[90  6  9]\n",
      " [ 2 84  9]\n",
      " [ 7  4 89]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88       105\n",
      "           1       0.89      0.88      0.89        95\n",
      "           2       0.83      0.89      0.86       100\n",
      "\n",
      "    accuracy                           0.88       300\n",
      "   macro avg       0.88      0.88      0.88       300\n",
      "weighted avg       0.88      0.88      0.88       300\n",
      "\n",
      "Accuracy: 0.88\n",
      "ROC-AUC: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "\n",
    "# Suppress undefined metric warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# Create a synthetic multi-class classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=3, n_informative=3, n_clusters_per_class=1, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the data using the min-max scaler\n",
    "norm = MinMaxScaler().fit(X_train) # This calculates the min and max values of each feature and records them for applicatin to future data\n",
    "X_train = norm.transform(X_train) # apply the scaler to the training data\n",
    "X_test = norm.transform(X_test) # apply the scaler to the testing data\n",
    "\n",
    "# Create and train the neural network model\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Binarize the labels for multi-class ROC AUC\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y))\n",
    "roc_auc = roc_auc_score(y_test_binarized, y_pred_proba, multi_class='ovr')\n",
    "\n",
    "# Performance metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.47404231, -0.17115639, -0.91720268, ...,  0.69606542,\n",
       "         -0.90385554, -0.46492617],\n",
       "        [ 0.74390168,  0.6181091 , -0.65280848, ..., -0.83270522,\n",
       "          0.38124427, -0.14311574],\n",
       "        [-0.83169229,  0.77588109, -1.68582364, ..., -2.42358281,\n",
       "          0.38999839,  0.34239935],\n",
       "        ...,\n",
       "        [-1.03963394,  2.39191993,  0.26427057, ...,  0.42108499,\n",
       "         -0.77446164,  0.03647218],\n",
       "        [ 0.33693433,  0.4313451 ,  2.09873235, ..., -1.26689671,\n",
       "         -1.38540939,  0.43866796],\n",
       "        [ 1.17522446,  0.68178318, -1.37225945, ...,  0.80181929,\n",
       "         -1.11325669, -1.49526606]]),\n",
       " array([0, 0, 2, 0, 1, 2, 1, 2, 1, 2, 0, 2, 0, 0, 1, 0, 0, 0, 2, 2, 2, 2,\n",
       "        1, 1, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 0, 1, 1, 1, 2, 1, 0, 1,\n",
       "        2, 1, 0, 1, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 1,\n",
       "        1, 1, 1, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 2, 2, 1, 2,\n",
       "        0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 2, 2, 2, 0, 1, 1, 2, 2, 0, 0, 2, 1,\n",
       "        0, 0, 0, 1, 0, 1, 0, 2, 0, 1, 1, 1, 0, 0, 2, 2, 2, 1, 1, 0, 1, 0,\n",
       "        2, 1, 1, 2, 0, 0, 0, 2, 2, 2, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 0, 0,\n",
       "        2, 0, 2, 0, 0, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 1, 0, 2,\n",
       "        1, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 1, 0, 2, 2, 2, 0, 0,\n",
       "        0, 1, 2, 2, 2, 1, 1, 0, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 2, 2, 0, 1,\n",
       "        0, 1, 1, 1, 2, 0, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 0, 2, 0, 2, 1,\n",
       "        1, 1, 1, 2, 2, 2, 1, 0, 1, 1, 0, 0, 1, 2, 2, 0, 1, 0, 1, 2, 0, 2,\n",
       "        1, 1, 0, 2, 1, 2, 1, 0, 2, 0, 1, 1, 1, 2, 1, 2, 0, 0, 0, 0, 1, 1,\n",
       "        2, 0, 1, 2, 0, 2, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 2,\n",
       "        1, 1, 2, 1, 0, 1, 2, 2, 1, 2, 0, 0, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2,\n",
       "        2, 2, 2, 0, 1, 2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 0, 1, 2, 0, 1, 1, 2,\n",
       "        0, 2, 2, 2, 0, 1, 0, 0, 2, 0, 0, 2, 2, 0, 1, 1, 0, 2, 2, 2, 0, 1,\n",
       "        0, 2, 1, 2, 0, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0,\n",
       "        2, 0, 0, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 0, 0, 0, 2, 2, 1, 0, 1, 1,\n",
       "        0, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 2, 2, 1, 0, 0, 0, 2, 1,\n",
       "        1, 0, 0, 2, 1, 1, 1, 2, 0, 1, 2, 0, 0, 0, 1, 1, 1, 0, 1, 1, 2, 1,\n",
       "        0, 1, 2, 2, 2, 0, 2, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0,\n",
       "        2, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 0, 0, 1, 1, 2, 1, 2,\n",
       "        2, 2, 0, 1, 2, 0, 2, 1, 2, 0, 1, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0,\n",
       "        0, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 0, 0, 2, 1, 1, 2, 0, 2, 1, 1, 1,\n",
       "        1, 2, 2, 1, 1, 1, 1, 0, 0, 1, 2, 1, 1, 0, 2, 0, 2, 2, 0, 2, 0, 0,\n",
       "        2, 2, 0, 1, 0, 2, 1, 2, 0, 1, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2,\n",
       "        0, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 1, 0,\n",
       "        1, 0, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 1, 1,\n",
       "        1, 0, 1, 2, 2, 1, 2, 0, 1, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 2, 0, 2,\n",
       "        0, 0, 2, 0, 1, 1, 1, 1, 0, 2, 2, 1, 2, 0, 0, 2, 0, 1, 1, 2, 1, 1,\n",
       "        1, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 2, 0, 0, 1, 1, 1, 2, 0, 0, 2,\n",
       "        2, 1, 0, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 0, 0, 2, 1, 1, 0, 0, 1,\n",
       "        2, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 2, 1, 1, 2, 2, 2, 1,\n",
       "        1, 0, 2, 0, 1, 2, 2, 1, 1, 0, 2, 2, 2, 0, 2, 0, 2, 2, 1, 1, 2, 1,\n",
       "        2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 1, 2, 1, 2, 1,\n",
       "        2, 2, 0, 1, 2, 0, 2, 1, 2, 1, 1, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 2,\n",
       "        2, 1, 2, 1, 1, 2, 2, 0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 0, 1,\n",
       "        1, 0, 0, 2, 0, 2, 0, 1, 0, 2, 2, 2, 0, 1, 2, 2, 2, 1, 0, 2, 0, 1,\n",
       "        1, 0, 0, 2, 1, 2, 1, 2, 1, 2, 0, 2, 0, 2, 1, 0, 0, 0, 0, 1, 1, 2,\n",
       "        1, 2, 2, 0, 1, 0, 2, 2, 0, 0, 1, 1, 2, 0, 0, 2, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 2, 1, 1, 2, 2, 1, 1, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1,\n",
       "        2, 0, 1, 1, 1, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 1,\n",
       "        0, 1, 0, 2, 2, 2, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1,\n",
       "        2, 2, 2, 0, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 2, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences In Multi Class Vs Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    X, y = make_classification(n_samples=1000, n_features=20, n_classes=3, n_informative=3, n_clusters_per_class=1, random_state=42)\n",
    "\n",
    "    \n",
    "    from sklearn.exceptions import UndefinedMetricWarning\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    y_test_binarized = label_binarize(y_test, classes=np.unique(y))\n",
    "    roc_auc = roc_auc_score(y_test_binarized, y_pred_proba, multi_class='ovr')\n",
    "\n",
    "        In the binary classification model, the ROC AUC was calculated directly from the binary predictions.\n",
    "        This change is necessary because ROC AUC calculation for multi-class classification requires binarized labels, and the roc_auc_score method is slightly different (multi_class='ovr' parameter).\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 5145.07\n",
      "R-squared (R2): 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_targets=1, noise=0.1, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the data using the min-max scaler\n",
    "norm = MinMaxScaler().fit(X_train) # This calculates the min and max values of each feature and records them for applicatin to future data\n",
    "X_train = norm.transform(X_train) # apply the scaler to the training data\n",
    "X_test = norm.transform(X_test) # apply the scaler to the testing data\n",
    "\n",
    "# Create and train the MLPRegressor model\n",
    "model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
