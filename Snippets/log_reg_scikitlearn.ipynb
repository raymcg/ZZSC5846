{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_file():\n",
    "  \n",
    "    iris = datasets.load_iris() # Source: https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "\n",
    "    #X = iris.data[:, np.newaxis, 2] # single factor \n",
    "    X = iris.data  # all factors\n",
    "    y = iris.target\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(150, 4)\n",
      "y.shape=(150,)\n",
      "First two x examples:\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]]\n",
      "First three y examples: \n",
      "[0 0 0]\n",
      "\n",
      "X.min()=0.1, X.max()=7.9\n",
      "y.min()=0, y.max()=2\n",
      "\n",
      "Unique y values: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "X,y = load_input_file()\n",
    "\n",
    "# Describe Dataset\n",
    "print(f\"{X.shape=}\")\n",
    "print(f\"{y.shape=}\")\n",
    "print(f\"First two x examples:\\n{X[:2]}\")\n",
    "print(f\"First three y examples: \\n{y[:3]}\")\n",
    "\n",
    "print(f\"\\n{X.min()=}, {X.max()=}\")\n",
    "print(f\"{y.min()=}, {y.max()=}\\n\")\n",
    "\n",
    "# give unique values of y\n",
    "print(f\"Unique y values: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error / Accuracy / Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_metrics(model, x_train, x_test, y_train, y_test):\n",
    "\n",
    "    \"\"\"\n",
    "        model input parameter is the fitted classification model\n",
    "    \"\"\"\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = model.predict(x_test) \n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Precision, Recall, F1-Score (across all classes if multiclass)\n",
    "    precision, recall, f1_score, _ = metrics.precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1_score:.4f}\")\n",
    "\n",
    "    # AUC-ROC (only for binary classification)\n",
    "    if len(np.unique(y_test)) == 2:\n",
    "        y_prob = model.predict_proba(x_test)[:, 1]  # Probabilities of the positive class\n",
    "        auc_roc = metrics.roc_auc_score(y_test, y_prob)\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    else:\n",
    "        auc_roc = None\n",
    "\n",
    "    # Confusion Matrix\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "\n",
    "    return accuracy, precision, recall, f1_score, auc_roc, confusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples:  150\n",
      "Number of Features:  4\n",
      "Accuracy: 0.9500\n",
      "Precision: 0.9511\n",
      "Recall: 0.9500\n",
      "F1-Score: 0.9501\n",
      "Confusion Matrix:\n",
      "[[23  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  2 19]]\n"
     ]
    }
   ],
   "source": [
    "def main(): \n",
    "\n",
    "    # Import data and load into X and y variables\n",
    "    X,y = load_input_file()\n",
    "\n",
    "    print(\"Number of Training Examples: \", X.shape[0])\n",
    "    print(\"Number of Features: \", X.shape[1])\n",
    "\n",
    "    # Normalize data\n",
    "    #   https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data set into training and testing sets: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=2)    \n",
    " \n",
    "    # Define Regularization Parameter\n",
    "    regularization = 'l2' # 'l1' or 'l2' or None\n",
    "    reg_tolerence = 0.01\n",
    "\n",
    "    # Define Which model to use and including the regularization parameter\n",
    "    if regularization == None: # No regularization\n",
    "        model = linear_model.LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "         #   https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    else: # With Regularization\n",
    "        model = linear_model.LogisticRegression(solver='lbfgs', C=1e5, multi_class='multinomial', penalty=regularization, tol=reg_tolerence)\n",
    "    \n",
    "    # Train the model using the training set\n",
    "    model.fit(x_train, y_train) \n",
    "\n",
    "    # Report Classification Metrics\n",
    "    accuracy, precision, recall, f1_score, auc_roc, confusion = logistic_metrics(model, x_train, x_test, y_train, y_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
