{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpath = \"c:\\\\dropbox\\\\variance\\\\unsw\\\\zzsc5836\\\\raw_data\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(run_num, prob):\n",
    "\n",
    "    normalise = False\n",
    "    \n",
    "    if prob == 'classifification': #Source:  Pima-Indian diabetes dataset: https://www.kaggle.com/kumargh/pimaindiansdiabetescsv\n",
    "        data_in = genfromtxt(fpath+\"pima.csv\", delimiter=\",\")\n",
    "        data_inputx = data_in[:,0:8] # all features 0, 1, 2, 3, 4, 5, 6, 7 \n",
    "        data_inputy = data_in[:,-1] # this is target - so that last col is selected from data\n",
    "\n",
    "    elif prob == 'regression': # energy - regression prob\n",
    "        data_in = genfromtxt(fpath+'ENB2012_data.csv', delimiter=\",\")  \n",
    "        data_inputx = data_in[:,0:8] # all features 0, - 7\n",
    "        data_inputy = data_in[:,8] # this is target - just the heating load selected from data\n",
    "  \n",
    "\n",
    "    if normalise == True:\n",
    "        transformer = Normalizer().fit(data_inputx)  # fit does nothing.\n",
    "        data_inputx = transformer.transform(data_inputx)\n",
    " \n",
    "\n",
    " \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_inputx, data_inputy, test_size=0.40, random_state=run_num)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    " \n",
    "    \n",
    "def scipy_models(x_train, x_test, y_train, y_test, type_model, hidden, learn_rate, run_num, problem):\n",
    "\n",
    "    print(run_num, ' is our exp run')\n",
    "\n",
    "    tree_depth = 2\n",
    " \n",
    "    if problem == 'classifification':\n",
    "        if type_model ==0: #SGD \n",
    "            model = MLPClassifier(hidden_layer_sizes=(hidden,), random_state=run_num, max_iter=100,solver='sgd',  learning_rate_init=learn_rate ) \n",
    "        elif type_model ==1: #https://scikit-learn.org/stable/modules/tree.html  (see how tree can be visualised)\n",
    "            model = DecisionTreeClassifier(random_state=0, max_depth=tree_depth)\n",
    "\n",
    "    elif problem == 'regression':\n",
    "        if type_model ==0: #SGD \n",
    "            #model = MLPRegressor(hidden_layer_sizes=(hidden,), random_state=run_num, max_iter=100,solver='sgd',  learning_rate_init=learn_rate ) \n",
    "\n",
    "            model = MLPRegressor(hidden_layer_sizes=(hidden*3,), random_state=run_num, max_iter=500, solver='adam',learning_rate_init=learn_rate) \n",
    "        elif type_model ==1: #https://scikit-learn.org/stable/modules/tree.html  (see how tree can be visualised)\n",
    "            model = DecisionTreeRegressor(random_state=0, max_depth=tree_depth)\n",
    "   \n",
    "    # Train the model using the training sets\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    if type_model ==1:\n",
    "        r = export_text(model)\n",
    "        # print(r) #print the tree\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    y_pred_train = model.predict(x_train) \n",
    "\n",
    "    if problem == 'regression':\n",
    "        perf_test =  np.sqrt(mean_squared_error(y_test, y_pred_test)) \n",
    "        perf_train=  np.sqrt(mean_squared_error(y_train, y_pred_train)) \n",
    "\n",
    "    if problem == 'classifification': \n",
    "        perf_test = accuracy_score(y_pred_test, y_test) \n",
    "        perf_train = accuracy_score(y_pred_train, y_train) \n",
    "        cm = confusion_matrix(y_pred_test, y_test) \n",
    "        #print(cm, 'is confusion matrix')\n",
    "        #auc = roc_auc_score(y_pred, y_test, average=None) \n",
    "\n",
    "    return perf_test #,perf_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifification  is our problem\n",
      "0  is our exp run\n",
      "0  is our exp run\n",
      "1  is our exp run\n",
      "1  is our exp run\n",
      "2  is our exp run\n",
      "2  is our exp run\n",
      "3  is our exp run\n",
      "3  is our exp run\n",
      "4  is our exp run\n",
      "4  is our exp run\n",
      "[0.66558442 0.6461039  0.66558442 0.59415584 0.66558442]  SGD_all\n",
      "0.6474025974025974  mean nn_all\n",
      "0.02767178669176953  std nn_all\n"
     ]
    }
   ],
   "source": [
    "max_expruns = 5\n",
    "\n",
    "SGD_all = np.zeros(max_expruns) \n",
    "Adam_all = np.zeros(max_expruns) \n",
    "tree_all = np.zeros(max_expruns)  \n",
    "\n",
    "learn_rate = 0.01\n",
    "hidden = 8\n",
    "\n",
    "prob = 'classifification' #  classification  or regression \n",
    "#prob = 'regression' #  classification  or regression \n",
    "\n",
    "\n",
    "# classifcation accurary is reported for classification and RMSE for regression\n",
    "\n",
    "print(prob, ' is our problem')\n",
    "\n",
    "\n",
    "for run_num in range(0,max_expruns): \n",
    "\n",
    "    x_train, x_test, y_train, y_test = read_data(run_num, prob)   \n",
    "    \n",
    "    acc_sgd = scipy_models(x_train, x_test, y_train, y_test, 0, hidden, learn_rate, run_num, prob) #SGD \n",
    "    acc_tree = scipy_models(x_train, x_test, y_train, y_test, 1, hidden, learn_rate,  run_num, prob) #Decision Tree\n",
    "    \n",
    "    SGD_all[run_num] = acc_sgd \n",
    "    tree_all[run_num] = acc_tree\n",
    "\n",
    "print(SGD_all,' SGD_all')\n",
    "print(np.mean(SGD_all), ' mean nn_all')\n",
    "print(np.std(SGD_all), ' std nn_all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72402597 0.70454545 0.73051948 0.71428571 0.78896104] 8  tree_all\n"
     ]
    }
   ],
   "source": [
    "print(tree_all, hidden,' tree_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7324675324675325  tree _all\n",
      "0.029586456493232507  tree _all\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(tree_all),  ' tree _all')\n",
    "print(np.std(tree_all),  ' tree _all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def random_forest(num_trees, num_leaves):\n",
    "\n",
    "    #rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=num_trees, max_leaf_nodes=num_leaves, n_jobs=-1)\n",
    "    rnd_clf.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_rf = rnd_clf.predict(x_test) # This gives us the predicted class for each of the 3 rows of data\n",
    "    #print(y_pred_rf)\n",
    "\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "    return acc_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra-Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "def extra_trees_func(num_trees, num_leaves):\n",
    "\n",
    "    #rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "    et_clf = ExtraTreesClassifier(n_estimators=num_trees, max_leaf_nodes=num_leaves, n_jobs=-1)    \n",
    "    et_clf.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_rf = et_clf.predict(x_test) # This gives us the predicted class for each of the 3 rows of data\n",
    "    #print(y_pred_rf)\n",
    "\n",
    "    acc_et = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "    return acc_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for Random Forests: [0.78246753 0.80844156 0.79545455], Mean: 0.7954545454545454\n",
      "Accuracy Scores for Extra Trees: [0.79545455 0.79220779 0.78246753], Mean: 0.79004329004329\n"
     ]
    }
   ],
   "source": [
    "num_tree_list = [20,40,60]\n",
    "acc_rf_all = np.zeros(len(num_tree_list))\n",
    "acc_et_all = np.zeros(len(num_tree_list))\n",
    "\n",
    "i = 0\n",
    "for num_trees in num_tree_list:\n",
    "\n",
    "    acc_rf_all[i] = random_forest(num_trees, 16)\n",
    "    acc_et_all[i] = extra_trees_func(num_trees, 16)\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "print(f\"Accuracy Scores for Random Forests: {acc_rf_all}, Mean: {np.mean(acc_rf_all)}\")\n",
    "print(f\"Accuracy Scores for Extra Trees: {acc_et_all}, Mean: {np.mean(acc_et_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
