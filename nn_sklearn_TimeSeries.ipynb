{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import mean_squared_error  \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "\n",
    "#keras \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253217\n",
    "\n",
    "fpath = 'C:\\\\Dropbox\\\\Variance\\\\UNSW\\\\ZZSC5836\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(run_num):\n",
    "    #Source - raw and processed data :  https://github.com/sydney-machine-learning/Bayesianneuralnet_stockmarket/tree/master/code/dataset\n",
    "    # five inputs (window size of 5) for 5 steps ahead (MMM dataset) https://finance.yahoo.com/quote/MMM/\n",
    "    #code to process raw data: https://github.com/sydney-machine-learning/Bayesianneuralnet_stockmarket/blob/master/code/data.py\n",
    "    data_in = genfromtxt(fpath+\"raw_data\\\\MMM8_train.txt\", delimiter=\" \")\n",
    "    data_inputx = data_in[:,0:5] # all features 0, 1, 2, 3, 4, 5, 6, 7 \n",
    "\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer\n",
    "    #transformer = Normalizer().fit(data_inputx)  # fit does nothing.\n",
    "    #data_inputx = transformer.transform(data_inputx)\n",
    "    data_inputy = data_in[:,5:10] # this is target - so that last col is selected from data\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_inputx, data_inputy, test_size=0.40, random_state=run_num)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    " \n",
    "    \n",
    "def nn(x_train, x_test, y_train, y_test, type_model, hidden):\n",
    " \n",
    "\n",
    "    timesteps = 5 # window size\n",
    "    #steps_ahead = 5 \n",
    "    steps_ahead = 5 # prediction horizon 1 \n",
    "\n",
    "    if type_model ==0: #keras Adam\n",
    "        nn = keras.Sequential()\n",
    "        nn.add(layers.Dense(hidden, input_dim=timesteps, activation='relu'))\n",
    "        nn.add(layers.Dense(steps_ahead, activation='sigmoid'))\n",
    "        nn.compile(loss=keras.losses.binary_crossentropy,optimizer='adam', metrics=[keras.metrics.RootMeanSquaredError(), keras.metrics.mae,keras.metrics.mape])\n",
    "         \n",
    "    else:\n",
    "        print('no model')    \n",
    "  \n",
    "    history = nn.fit(x_train, y_train, epochs=500, batch_size=32, verbose=0)#callbacks=[fa_test_his])\n",
    "    y_pred_test = nn.predict(x_test)\n",
    "    n = len(y_test)\n",
    "    MAE = sum(np.abs(y_test - y_pred_test)) / n \n",
    "    RMSE_horizon1 = np.sqrt(sum(np.square(y_test[:,0] - y_pred_test[:,0])) / n) # prediction horizon 1\n",
    "\n",
    "    RMSE = np.sqrt(sum(np.square(y_test - y_pred_test)) / n) \n",
    "    MAPE=sum(np.abs((y_test - y_pred_test) / (y_test + 1e-6))) / n * 100  \n",
    "   \n",
    "    return RMSE, RMSE_horizon1, y_test, y_pred_test, MAPE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 620us/step\n",
      "11/11 [==============================] - 0s 598us/step\n",
      "rmse_all=array([0.08129776, 0.08015849]), mape_all=array([292.14145439, 294.99881429]), hidden=6, Accuracy, MAPE all runs\n",
      "np.mean(mape_all)=293.57013434115254, hidden=6 mape\n",
      "np.mean(rmse_all)=0.08072812545481084, hidden=6 rmse\n",
      "np.mean(rmse_horizon1_all)=0.03461283946723716, hidden=6 rmse_horizon1\n",
      "proportion_of_range_full=0.08081394986957233, proportion_of_std_dev_full=0.3174495299622255\n",
      "proportion_of_range_first=0.034649637382136986, proportion_of_std_dev_first=0.13610906431467998\n",
      "11/11 [==============================] - 0s 598us/step\n",
      "11/11 [==============================] - 0s 603us/step\n",
      "rmse_all=array([0.08013774, 0.04540305]), mape_all=array([291.33346577,  80.06800257]), hidden=8, Accuracy, MAPE all runs\n",
      "np.mean(mape_all)=185.7007341667431, hidden=8 mape\n",
      "np.mean(rmse_all)=0.06277039496745437, hidden=8 rmse\n",
      "np.mean(rmse_horizon1_all)=0.02556539299054058, hidden=8 rmse_horizon1\n",
      "proportion_of_range_full=0.0628371279973876, proportion_of_std_dev_full=0.24683382979226798\n",
      "proportion_of_range_first=0.025592572302325648, proportion_of_std_dev_first=0.10053153027428609\n"
     ]
    }
   ],
   "source": [
    "max_expruns = 2\n",
    "\n",
    "Adam_all_acc = np.zeros(max_expruns) \n",
    "mape_all = np.zeros(max_expruns) \n",
    "rmse_all = np.zeros(max_expruns) \n",
    "rmse_horizon1_all = np.zeros(max_expruns) \n",
    "    \n",
    "max_hidden = 10\n",
    "\n",
    "for hidden in range(6,max_hidden, 2):\n",
    "\n",
    "    for run_num in range(0,max_expruns): \n",
    "\n",
    "        x_train, x_test, y_train, y_test = read_data(0)   \n",
    "\n",
    "        rmse, RMSE_horizon1, y_test, y_pred_test, mape = nn(x_train, x_test, y_train, y_test, 0, hidden) \n",
    "            \n",
    "        mape_all[run_num] = mape\n",
    "        rmse_all[run_num] = rmse\n",
    "        rmse_horizon1_all[run_num] = RMSE_horizon1\n",
    "\n",
    "    print(f\"{rmse_all=}, {mape_all=}, {hidden=}, Accuracy, MAPE all runs\")\n",
    "    #print(f\"{np.std(Adam_all_acc)=}, {hidden=} std\")\n",
    "    print(f\"{np.mean(mape_all)=}, {hidden=} mape\")\n",
    "    print(f\"{np.mean(rmse_all)=}, {hidden=} rmse\")\n",
    "    print(f\"{np.mean(rmse_horizon1_all)=}, {hidden=} rmse_horizon1\")\n",
    "\n",
    "    # Put rmse values into context\n",
    "    range_target = np.max(y_train) - np.min(y_train)\n",
    "    std_dev_target = np.std(y_train)\n",
    "    proportion_of_range_full = np.mean(rmse_all) / range_target\n",
    "    proportion_of_std_dev_full = np.mean(rmse_all) / std_dev_target\n",
    "    proportion_of_range_first = np.mean(rmse_horizon1_all) / range_target\n",
    "    proportion_of_std_dev_first = np.mean(rmse_horizon1_all) / std_dev_target\n",
    "    print(f\"{proportion_of_range_full=}, {proportion_of_std_dev_full=}\")\n",
    "    print(f\"{proportion_of_range_first=}, {proportion_of_std_dev_first=}\")\n",
    "\n",
    "\n",
    "#next try a paragraph to describe your results and discuss which models are better to use.\n",
    "#repeat for another dataset\n",
    "# you can save results to a file as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (482, 5) y_train shape: (482, 5)\n",
      "x_train\n",
      "[[0.149406 0.1466   0.144777 0.144105 0.150437]\n",
      " [0.136047 0.136431 0.148135 0.146696 0.143866]]\n",
      "y_train\n",
      "[[0.148231 0.149622 0.144105 0.145736 0.142906]\n",
      " [0.138158 0.148566 0.147751 0.151972 0.157056]]\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape, 'y_train shape:', y_train.shape)\n",
    "print('x_train')\n",
    "print(x_train[:2])\n",
    "print('y_train')\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of How the Code Works:\n",
    "\n",
    "    Data Reading and Preprocessing:\n",
    "        The function read_data reads input data from a file, splits it into features (data_inputx) and targets (data_inputy), and then divides these into training and testing sets using train_test_split.\n",
    "\n",
    "    Neural Network Model Definition and Training:\n",
    "        The function nn defines and trains a neural network model. The model is a sequential Keras model with one hidden layer (Dense) and an output layer. It uses 'relu' activation for the hidden layer and 'sigmoid' for the output layer.\n",
    "        The model is compiled with a binary cross-entropy loss function and the Adam optimizer.\n",
    "        It is trained on the training data and then used to predict on the test data. Various performance metrics like Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE) are calculated.\n",
    "\n",
    "    Main Execution Loop:\n",
    "        The main function runs several experiments (max_expruns) with varying numbers of hidden neurons (max_hidden) in the neural network. For each configuration, it evaluates the model's performance using the RMSE metric.\n",
    "        The results (RMSE values) across different runs and configurations are printed out for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Descriptions:\n",
    "\n",
    "    run_num: A parameter in read_data function, likely used to set a random seed for reproducibility.\n",
    "    data_in: The dataset loaded from a file.\n",
    "    data_inputx: The input features extracted from data_in.\n",
    "    data_inputy: The target values (labels) extracted from data_in.\n",
    "    x_train, x_test, y_train, y_test: Data split into training and testing sets.\n",
    "    type_model: A parameter in the nn function, used to select the type of model (only '0' is used, representing Keras with Adam optimizer).\n",
    "    hidden: The number of neurons in the hidden layer of the neural network.\n",
    "    nn: The neural network model.\n",
    "    timesteps, steps_ahead: Constants defining the window size and prediction horizon respectively.\n",
    "    Adam_all: An array to store RMSE values for different runs.\n",
    "    max_expruns, max_hidden: Variables controlling the number of experiments and the range of hidden neurons to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapes of Input and Target Factors:\n",
    "\n",
    "    Input (Features) Shape: The input data (data_inputx) is derived from the dataset with a shape of [number of samples, 5]. This shape is because the model uses a window size of 5 timesteps.\n",
    "    Target (Labels) Shape: The target data (data_inputy) is also derived from the dataset with a shape of [number of samples, 5]. This shape is because the model predicts values 5 steps ahead, as indicated by steps_ahead.\n",
    "\n",
    "The target factor has this shape to match the model's output, which is predicting values for 5 future steps, aligning with the problem of predicting future stock prices for a given number of future time steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
