{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_data():\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    y[y != 0] = -1  # Convert to binary classification problem for simplicity\n",
    "    y[y == 0] = 1\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def stump_classifier(X, y, weights):\n",
    "    m, n = X.shape\n",
    "    best_stump = {}\n",
    "    min_error = float('inf')\n",
    "\n",
    "    for j in range(n):  # Loop over all features\n",
    "        feature_values = np.sort(np.unique(X[:, j]))\n",
    "        thresholds = (feature_values[:-1] + feature_values[1:]) / 2\n",
    "        for threshold in thresholds:\n",
    "            for inequality in [\"lt\", \"gt\"]:  # Check both directions\n",
    "                predictions = np.ones(m)\n",
    "                if inequality == \"lt\":\n",
    "                    predictions[X[:, j] <= threshold] = -1\n",
    "                else:\n",
    "                    predictions[X[:, j] > threshold] = -1\n",
    "\n",
    "                error = np.sum(weights[y != predictions])\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                    best_stump[\"dim\"] = j\n",
    "                    best_stump[\"thresh\"] = threshold\n",
    "                    best_stump[\"ineq\"] = inequality\n",
    "\n",
    "    return best_stump, min_error\n",
    "\n",
    "def adaboost_train(X, y, M=50):\n",
    "    weak_classifiers = []\n",
    "    m = X.shape[0]\n",
    "    D = np.ones(m) / m  # Initialize weights\n",
    "\n",
    "    for i in range(M):\n",
    "        stump, error = stump_classifier(X, y, D)\n",
    "        alpha = 0.5 * np.log((1 - error) / max(error, 1e-10))\n",
    "        stump[\"alpha\"] = alpha\n",
    "        weak_classifiers.append(stump)\n",
    "\n",
    "        # Update weights\n",
    "        predictions = np.ones(m)\n",
    "        if stump[\"ineq\"] == \"lt\":\n",
    "            predictions[X[:, stump[\"dim\"]] <= stump[\"thresh\"]] = -1\n",
    "        else:\n",
    "            predictions[X[:, stump[\"dim\"]] > stump[\"thresh\"]] = -1\n",
    "\n",
    "        D *= np.exp(-alpha * y * predictions)\n",
    "        D /= D.sum()\n",
    "\n",
    "    return weak_classifiers\n",
    "\n",
    "def adaboost_predict(X, weak_classifiers):\n",
    "    m = X.shape[0]\n",
    "    predictions = np.zeros(m)\n",
    "\n",
    "    for stump in weak_classifiers:\n",
    "        stump_predictions = np.ones(m)\n",
    "        if stump[\"ineq\"] == \"lt\":\n",
    "            stump_predictions[X[:, stump[\"dim\"]] <= stump[\"thresh\"]] = -1\n",
    "        else:\n",
    "            stump_predictions[X[:, stump[\"dim\"]] > stump[\"thresh\"]] = -1\n",
    "\n",
    "        predictions += stump[\"alpha\"] * stump_predictions\n",
    "\n",
    "    return np.sign(predictions)\n",
    "\n",
    "# Load data\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "# Train AdaBoost\n",
    "weak_classifiers = adaboost_train(X_train, y_train, M=50)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = adaboost_predict(X_test, weak_classifiers)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- `load_data`: Loads the Iris dataset and converts it into a binary classification problem for simplicity.\n",
    "- `stump_classifier`: Creates a decision stump. It finds the best feature and threshold to split the data to minimize weighted classification error.\n",
    "- `adaboost_train`: Implements the AdaBoost algorithm. It iteratively creates decision stumps, updates weights of training instances, and calculates the alpha values (which represent the weight of each stump in the final classification).\n",
    "- `adaboost_predict`: Makes predictions using the ensemble of stumps created during training.\n",
    "- Finally, the script trains the AdaBoost model on the Iris dataset and evaluates its accuracy.\n",
    "\n",
    "Remember, this is a basic implementation and lacks many features and optimizations of professional libraries. However, it should give you a conceptual understanding of how AdaBoost works under the hood."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
